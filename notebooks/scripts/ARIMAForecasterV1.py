from .arima_import import *
from dataclasses import dataclass, field
from itertools import combinations
from scipy.stats import t



@dataclass
class SARIMAForcaster:
    """
    SARIMAX Forecaster dataclass with SARIMAX time series model adapted from statsmodel.tsa.SARIMAX library
    """
    
    df: pd.DataFrame
    
    endog: str  # the observed time-series process y
    exog: list[str]  # array of exogenous regressors, shaped nobs x k
    
    ## The (p, d, q) order of the model for the number of AR parameters, differences and MA parameters.
    ## p, d, q must be integers
    order: tuple = (1, 0, 0)  
    
    ## The (P, D, Q, s) order of the seasonal component of the moel for the AR parameters
    ## differences MA parameters and periodicity.
    seasonal_order: tuple = (0, 0, 0, 0)
    
    # kwargs for SARIMAX, https://www.statsmodels.org/stable/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html
    kwargs: dict = field(default_factory=lambda: dict(trend=None, 
                                                      measurement_error=None,
                                                      time_varying_regression=False,
                                                      mle_regression=True,
                                                      simple_differencing=False,
                                                      enforce_stationarity=True,
                                                      enforce_invertibility=True,
                                                      hamilton_representation=False,
                                                      concentrate_scale=False,
                                                      trend_offset=1,
                                                      use_exact_diffuse=False,
                                                      dates=None,
                                                      freq=None,
                                                      missing='none',
                                                      validate_sepecification=True))
    
    # maximum history for training
    max_history: int = 60 
        
    def __post_init__(self):
        self.df.index = pd.to_datetime(self.df.index)
        self.df.index.freq = 'MS'
        
    def one_step_ahead_forecasting(self, date, with_exog=False) -> float:
        """
        Single point one_step_ahead_forecasting function for a given date
        Args:
            date (str): start date string
            with_exog (bool=Flase): paramter enable the model train with exog factor or not
        Return:
            forecast (float) value
        """
        # find the start and end date range
        date = pd.to_datetime(date)
        start = date - pd.DateOffset(months=self.max_history)

        # locate the training set
        train_set = self.df[[f"lr_{self.endog}"]].loc[start:date].dropna()
    
        # with_exog will enable when finding the best lag order
        if with_exog:
            exog_train = self.df[self.exog].loc[start:date].dropna()
            exog_forecast = self.df[self.exog].loc[date + pd.DateOffset(months=1)]
        else:
            exog_train, exog_forecast = None, None
        

        # model training
        model = SARIMAX(endog=train_set, exog=exog_train, order=self.order)
        model_fit = model.fit(disp=False)
        
        # compute the forecast value
        forecast = model_fit.get_forecast(steps=1, exog=exog_forecast)
        
        return forecast.predicted_mean[0]
        
    def one_step_ahead_forecastings(self, date: dict, with_exog=False) -> list[float]:
        """
        Date range forecasting function based on single point one_step_ahead_forecasting function
        Args:
            date (dict): a dictionary contains start and end date info
            with_exog (bool=Flase): paramter enable the model train with exog factor or not
        Return (list[float]):
        """
        # find the start and end date range
        start_date, end_date = pd.to_datetime(date['start']), pd.to_datetime(date['end'])
        dates = pd.date_range(start=start_date, end=end_date, freq='MS')
        
        # compute forecast values
        forecasts = []
        for dt in dates:
            forecast = self.one_step_ahead_forecasting(dt, with_exog)
            forecasts.append(forecast)
        return forecasts
    
    def evaluate_matrix(self, forecasts: list[float], date: dict, standardised=True) -> tuple[float]:
        """
        Compute the evaluation matrix including RMSE, MAE and Correlation cofficient
        Args:
            forecasts (list[float]): forecasts value generated by one_step_ahead_forecasts funtions
            date (dict): a dictionary contains start and end date info
            standardised bool = True: a parameter enable the function to standardized the evaluation matrix value
        Return (tuple):
            (RMSE, MASE, Corr)
        """
        start_date, end_date = pd.to_datetime(date['start']), pd.to_datetime(date['end'])
        actual = self.df[[f"lr_{self.endog}"]].loc[start_date:end_date]
        
        # standardised evaluation values 
        self.std = np.std(self.df[[f'lr_{self.endog}']]).values[0] if standardised else 1 
        std = self.std 
        
        # compute rmse and mae 
        rmse = np.sqrt(mean_squared_error(actual, forecasts)) / std
        mae = mean_absolute_error(actual, forecasts) / std
        
        # compute the correlation between testing set and actual data
        # corr = np.correlate(actual.values.ravel(), forecasts)[0]  # either [0, 1] or [1, 0] work
        
        corr = np.corrcoef(actual.values.ravel(), forecasts)[0, 1]
        
        return rmse, mae, corr
        
    def plot_predictions(self, forecasts, date: dict, savefig=False, savepath="", standardised=True):
        """
        Plot forecast values against true values
        
        Args:
            forecasts (list[float]): forecasts value generated by one_step_ahead_forecasts funtions
            date (dict): a dictionary contains start and end date info
            savefig (bool = False): savefig option
            savepath (str): if savefig is True, user must provide savepath
            standardised bool = True: a parameter enable the function to standardized the evaluation matrix value   
        """
        if savefig and not savepath:
            raise ValueError("You must provide a path to save the figure when savefig is set to True.")
        
        # find start and end date range, locate the actual value and obtain evaluate matrix scores
        start_date, end_date = pd.to_datetime(date['start']), pd.to_datetime(date['end'])
        actual = self.df[[f'lr_{self.endog}']].loc[start_date:end_date]
        rmse, mae, corr = self.evaluate_matrix(forecasts, date, standardised)
        
        # generate the plot
        plt.figure(figsize=(10, 5))
        plt.plot(self.df.loc[start_date:end_date].index, self.df.loc[start_date:end_date][f'lr_{self.endog}'], label='True value')
        plt.plot(self.df.loc[start_date:end_date].index, forecasts, color='red', label='Predictions')
        
        title = f"One-step ahead forecasts (order: {self.order}, RMSE/STD: {rmse:.3f}, MAE/STD: {mae:.3f}, Correlation Coefficient: {corr:.3f})"

        if not standardised:
            title = title.replace('/STD', '')

        plt.title(title)
        plt.xlabel('Date')
        plt.ylabel('Log return')
        plt.legend()
        
        plt.tight_layout()
        if savefig:
            plt.savefig(savepath, dpi=300)
        plt.show()
        
    def find_the_optimal_lag_for_a_commodity(self, date, order_range=range(1, 25), standardised=True, best_order_matrix="RMSE") -> pd.DataFrame:
        """
        The function will find the optimal lag for a commodities based on RMAE, MAE and correlation coefficient values
        Args:
            date (dict): a dictionary contains start and end date info
            order_range (range(int)=range(1, 25)): range of order for searching
            standardised (bool) = True: a parameter enable the function to standardized the evaluation matrix value
            best_order_matrix (str): a string value specified which evaluation matrix should be used to determine the best lag, options: ['RMSE', 'MAE', 'Correlation']
        """

        # define the evaluation results list
        rmse_list, mae_list, corr_list, lower_ci_list, upper_ci_list = [], [], [], [], []

        # define the test data
        start_date, end_date = pd.to_datetime(date['start']), pd.to_datetime(date['end'])

        for p in tqdm(order_range, desc="Processing lag values"):
            self.order = (p, 0, 0)
            forecasts = self.one_step_ahead_forecastings(date, with_exog=False)
            rmse, mae, corr = self.evaluate_matrix(forecasts, date, standardised=True)

            # Calculate the confidence interval for the correlation
            alpha = 0.05
            n = len(forecasts)
            lower_ci, upper_ci = correlation_confidence_interval(corr, n, alpha)

            rmse_list.append(rmse)
            mae_list.append(mae)
            corr_list.append(corr)
            lower_ci_list.append(lower_ci)
            upper_ci_list.append(upper_ci)

        # generate a result dataframe
        results_df = pd.DataFrame({
            'Lag Order (p)': order_range,
            'RMSE': rmse_list,
            'MAE': mae_list,
            'Correlation': corr_list,
            'Lower CI': lower_ci_list,
            'Upper CI': upper_ci_list
        })

        # find the optimal lag and set as the default value
        min_index = results_df[[best_order_matrix]].idxmin()
        optim_p = results_df.loc[min_index]
        self.order = (optim_p['Lag Order (p)'].values[0], self.order[1], self.order[2])

        return results_df

    
    def plot_order_performance_without_exog(self, results_df, best_order_metric: str='RMSE', savefig: bool=False, savepath=""):
        """
        Plot order performance without Exogenous factor
        Args:
            results_df (pd.DataFrame): dataframe contains evaluation values (RMSE, MAE, correlation)
            savefig (bool = False): savefig option
            savepath (str): if savefig is True, user must provide savepath
            best_order_metric (str): RMSE or MAE
        Return:
            pyplot.plot
        """

        if savefig and not savepath:
            raise ValueError("You must provide a path to save the figure when savefig is set to True.")

        fig, ax = plt.subplots(1, 2, figsize=(10, 5)) # create figure and axis objects

        if best_order_metric == 'RMSE':
            plot_sub_plots(results_df, ax[0], 'RMSE', 'RMSE/STD', 'RMSE Different Lag Orders (p)', 'blue')
        else:
            plot_sub_plots(results_df, ax[0], 'MAE', 'MAE/STD', 'MAE for Different Lag Orders (p)', 'orange')
        
        plot_sub_plots(results_df, ax[1], 'Correlation', 'Correlation', 'Correlation for Different Lag Orders (p)', 'green')

        plt.tight_layout()
        if savefig:
            plt.savefig(savepath, dpi=300)
        plt.show()
                
    def generate_possible_factor_combinations(self, order_range: range=range(1, 25)):
        """
        Find optimal lag for selected climate factor, consider all possible combinations of climate lags
        """
        
        possible_combinations = []
        for lag in order_range:
            possible_combinations.append(list(combinations(self.exog, lag)))
        
        return possible_combinations

    def find_best_enso_lag(self, date):
        rmse_list, mae_list, corr_list = [], [], []
        start_date, end_date = pd.to_datetime(date['start']), pd.to_datetime(date['end'])
        
        exogs = self.exog        
        for e in exogs:
            self.exog = e
            forecasts = self.one_step_ahead_forecastings(date, with_exog=True)
            rmse, mae, corr = self.evaluate_matrix(forecasts, date, standardised=True)
        
            rmse_list.append(rmse)
            mae_list.append(mae)
            corr_list.append(corr)
            
        # generate a result dataframe
        results_df = pd.DataFrame({
            'Lag Order (p)': range(1, len(exogs) + 1),
            'RMSE': rmse_list,
            'MAE': mae_list,
            'Correlation': corr_list,
        })
        
        self.exog = exogs  # reset parameters

        return results_df
    
    def find_best_enso_lag_combinations(self, date):
        rmse_list, mae_list, corr_list = [], [], []
        start_date, end_date = pd.to_datetime(date['start']), pd.to_datetime(date['end'])
        
        exogs = list(combinations(self.exog, 1)) + list(combinations(self.exog, 2)) + list(combinations(self.exog, 3))
        print(len())
        
#         for e in exogs:
#             self.exog = e
#             forecasts = self.one_step_ahead_forecastings(date, with_exog=True)
#             rmse, mae, corr = self.evaluate_matrix(forecasts, date, standardised=True)
        
#             rmse_list.append(rmse)
#             mae_list.append(mae)
#             corr_list.append(corr)
            
#         # generate a result dataframe
#         results_df = pd.DataFrame({
#             'Lag Order (p)': range(1, len(exogs) + 1),
#             'RMSE': rmse_list,
#             'MAE': mae_list,
#             'Correlation': corr_list,
#         })
        
#         self.exog = exogs  # reset parameters

#         return results_df
    
    def plot_best_lag_for_enso(self, results_df, best_order_metric="RMSE", savefig: bool=False, savepath=""):
        """
        Plot the best lag results for ENSO based on a specified evaluation metric.
        Args:
            results_df (pd.DataFrame): dataframe contains evaluation values (RMSE, MAE, correlation)
            best_order_metric (str): evaluation metric to determine the best lag. Options: ['RMSE', 'MAE', 'Correlation']
            savefig (bool = False): savefig option
            savepath (str): if savefig is True, user must provide savepath
            best_order_metric (str): RMSE or MAE
        Return:
            pyplot.plot
        """

        if savefig and not savepath:
            raise ValueError("You must provide a path to save the figure when savefig is set to True.")

        fig, ax = plt.subplots(1, 2, figsize=(10, 5)) # create figure and axis objects

        # Determine the best lag based on the chosen metric
        if best_order_metric == "RMSE":
            best_lag_index = results_df["RMSE"].idxmin()
            plot_sub_plotsV1(results_df, ax[0], 'RMSE', 'RMSE/STD', 'RMSE for Different Lag Orders (p)', 'blue')
        elif best_order_metric == "MAE":
            best_lag_index = results_df["MAE"].idxmin()
            plot_sub_plotsV1(results_df, ax[0], 'MAE', 'MAE/STD', 'MAE for Different Lag Orders (p)', 'orange')
        elif best_order_metric == "Correlation":
            best_lag_index = results_df["Correlation"].idxmax()
        else:
            raise ValueError("Invalid best_order_metric. Choose from ['RMSE', 'MAE', 'Correlation']")

        best_lag = results_df.loc[best_lag_index, 'Lag Order (p)']
        
        plot_sub_plotsV1(results_df, ax[1], 'Correlation', 'Correlation', 'Correlation for Different Lag Orders (p)', 'green')

        plt.tight_layout()
        if savefig:
            plt.savefig(savepath, dpi=300)
        plt.show()
        
        
    
    def plot_order_performance_with_CI(self, results_df, date, savefig: bool=False, savepath=""):
        
        # https://stats.stackexchange.com/questions/368404/confidence-intervals-for-autocorrelation-function
        fig, ax = plt.subplots(1, 2, figsize=(10, 5))

        # Assuming the self object has methods to generate predictions for each lag order
        n_bootstrap = 1000  # Adjust this for computational efficiency vs accuracy trade-off

        for lag in results_df['Lag Order (p)']:
            start_date, end_date = pd.to_datetime(date['start']), pd.to_datetime(date['end'])
            test_data = self.df[f'lr_{self.endog}'].loc[start_date:end_date]
            predictions = self.one_step_ahead_forecastings(date, with_exog=False)

            # Bootstrap confidence intervals for RMSE
            rmse_bootstrap = [np.sqrt(np.mean((np.random.choice(test_data - predictions, len(test_data), replace=True))**2)) for _ in range(n_bootstrap)]
            rmse_CI = (np.percentile(rmse_bootstrap, 2.5) / self.std, np.percentile(rmse_bootstrap, 97.5) / self.std)

            # Bootstrap confidence intervals for MAE
            mae_bootstrap = [np.mean(np.abs(np.random.choice(test_data - predictions, len(test_data), replace=True))) for _ in range(n_bootstrap)]
            mae_CI = (np.percentile(mae_bootstrap, 2.5), np.percentile(mae_bootstrap, 97.5))

            # Confidence interval for Correlation using Fisher Z transformation
            corr = np.correlate(test_data, predictions)[0]
            z = 0.5 * np.log((1 + corr) / (1 - corr))
            se = 1 / np.sqrt(len(test_data) - 3)
            z_ci = t.ppf(1 - 0.025, df=len(test_data)-2) * se
            corr_CI = (np.tanh(z - z_ci), np.tanh(z + z_ci))

        # Plotting the metrics with confidence intervals
        ax[0].plot(results_df['Lag Order (p)'], results_df['RMSE'], label='RMSE', color='blue')
        ax[0].fill_between(results_df['Lag Order (p)'], rmse_CI[0], rmse_CI[1], color='blue', alpha=0.2)

        ax[0].plot(results_df['Lag Order (p)'], results_df['MAE'], label='MAE', color='orange')
        ax[0].fill_between(results_df['Lag Order (p)'], mae_CI[0], mae_CI[1], color='orange', alpha=0.2)

        ax[1].plot(results_df['Lag Order (p)'], results_df['Correlation'], label='Correlation', color='green')
        ax[1].fill_between(results_df['Lag Order (p)'], corr_CI[0], corr_CI[1], color='green', alpha=0.2)

        # ... [Rest of your plotting code for setting labels, titles, etc.]

        plt.tight_layout()
        if savefig:
            plt.savefig(savepath, dpi=300)
        plt.show()

## ============================== EXTERNAL FUNCTIONS ==============================

def correlation_confidence_interval(r, n, alpha):
    """
    Code Adapted from:
    https://stackoverflow.com/questions/33176049/how-do-you-compute-the-confidence-interval-for-pearsons-r-in-python
    """
    z = 0.5 * np.log((1 + r) / (1 - r))
    se = 1 / np.sqrt(n - 3)
    margin = t.ppf(1 - alpha / 2, df=n - 2) * se
    lower_bound = np.tanh(z - margin)
    upper_bound = np.tanh(z + margin)
    return lower_bound, upper_bound

def plot_sub_plots(results_df, ax, data, label, title, color):
    ax.plot(results_df['Lag Order (p)'], results_df[data], label=label, color=color)

    if data in ['RMSE', 'MAE']:
        min_point_index = results_df[data].idxmin()
        ax.plot(results_df.loc[min_point_index, 'Lag Order (p)'], 
                results_df.loc[min_point_index, data], 
                marker='o', color='red', markersize=10, label='Min ' + label)
    else:
        max_point_index = results_df[data].idxmax()
        ax.plot(results_df.loc[max_point_index, 'Lag Order (p)'], 
                results_df.loc[max_point_index, data], 
                marker='o', color='red', markersize=10, label='Max ' + label)
        
        # plotting the confidence interval for correlation
        # ax.fill_between(results_df['Lag Order (p)'], results_df['Lower CI'], results_df['Upper CI'], color='grey', alpha=0.5, label='95% CI')

    ax.set_xlabel('Lag Order (p)')
    ax.set_ylabel(label)
    ax.set_title(title)
    ax.legend()
    ax.grid(True)

    # Set integer ticks for x and y axes
    ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True))
    ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))
    
    
def plot_sub_plotsV1(results_df, ax, data, label, title, color):
    ax.plot(results_df['Lag Order (p)'], results_df[data], label=label, color=color)

    if data in ['RMSE', 'MAE']:
        min_point_index = results_df[data].idxmin()
        ax.plot(results_df.loc[min_point_index, 'Lag Order (p)'], 
                results_df.loc[min_point_index, data], 
                marker='o', color='red', markersize=10, label='Min ' + label)
    else:
        max_point_index = results_df[data].idxmax()
        ax.plot(results_df.loc[max_point_index, 'Lag Order (p)'], 
                results_df.loc[max_point_index, data], 
                marker='o', color='red', markersize=10, label='Max ' + label)

    ax.set_xlabel('Lag Order (p)')
    ax.set_ylabel(label)
    ax.set_title(title)
    ax.legend()
    ax.grid(True)

    # Set integer ticks for x and y axes
    ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True))
    ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))
    
def compute_acse_and_ci(AC, N):
    """
    Compute the Autocorrelation Standard Error and Confidence Interval.
    Args:
        AC (list): Autocorrelations at lags 0, 1, ..., k
        N (int): Sample size
    Returns:
        ACSE (list): Autocorrelation standard error for lags 1 to k
        CI (list): Confidence intervals for lags 1 to k
    """
    ACSE = []
    CI = []
    
    for k in range(1, len(AC)):
        acse_k = np.sqrt((N - 1) * (1 + 2 * np.sum(np.array(AC[1:k+1])**2)) / N)
        ci_lower = AC[k] - 1.96 * acse_k / np.sqrt(N)
        ci_upper = AC[k] + 1.96 * acse_k / np.sqrt(N)
        
        ACSE.append(acse_k)
        CI.append((ci_lower, ci_upper))
    
    return ACSE, CI